{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to `pandas` dataframes in Python\n",
    "\n",
    "## Overview\n",
    "You can use Python as part of your workflow to look at, transform, and analyze data!\n",
    "\n",
    "[`pandas`](https://pandas.pydata.org/docs/) is a library for the Python programming language. It provides you with high-performance data structures and data analysis tools. \n",
    "\n",
    "We're going to use dataframes to work with tabular data, that's data structured into columns and rows. Think:\n",
    "\n",
    "- Spreadsheets in Excel; \n",
    "- Comma-seperated value (CSV) and tab-seperated value (TSV) plain-text files;\n",
    "- Tables in a relational database.\n",
    "\n",
    "## Datasets\n",
    "We can find data from the Hack HPC [data list](http://hackhpc.org/data/). I found the Governor's Office of Planning and Budget \"Housing Units by County 2000-2011\" [dataset](https://opb.georgia.gov/social-and-economic-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from a flat file into a dataframe\n",
    "\n",
    "Take a tabular file type (CSV, TSV, XLS, XLSX) and put it into a dataframe object to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `pandas` module so that we can use it's functions and objects.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from an Excel file into a new `pandas` dataframe object.\n",
    "housing_df = pd.read_excel(\"Housing_Units-2000-2011.xls\")\n",
    "\n",
    "# Look at what's in the dataframe object.\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a dataframe header\n",
    "\n",
    "Something strange seems to be happening. We see what appear to be the years in the first row of data. And the header has column names that include \"Unnamed: #\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data from an Excel file into a new `pandas` dataframe object.\n",
    "# This time, specify the header from the original file.\n",
    "housing_df = pd.read_excel(\"Housing_Units-2000-2011.xls\", header=1)\n",
    "\n",
    "# Look at what's in the dataframe object.\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing column names\n",
    "Now the first column is \"Unamed: 0\", but we saw that it originally said \"Housing Units Estimates: Georgia Counties, 2000-2011\", and it seems to include the name of the county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename a column and assign the resulting dataframe back to the same variable.\n",
    "housing_df = housing_df.rename(columns={\"Unnamed: 0\": \"county_name\",})\n",
    "\n",
    "# Look at what's in the dataframe object.\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing rows using positional indexes\n",
    "The data still look a little messy, we have:\n",
    "\n",
    "- The first row with data for all of Georgia instead of just one county;\n",
    "- A row filled with \"NaN\";\n",
    "- The last row with information about where the data came from (aka metadata refering to the data source).\n",
    "\n",
    "We can grab only the rows we care about, this is called \"slicing\". In this case we will use the the \"positional index\" of the rows to specify what we want to keep. \n",
    "\n",
    "On the left-hand side of the dataframe, we see that that `pandas` automatically added a numeric index in bold (the column without a name). We can use this number to get at a particular row or range of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example of slicing a dataframe by specifying rows.\n",
    "housing_df[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- Positional indexes start at '0'.\n",
    "- Slicing by index is exclusive of the last index specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Slice a dataframe and assign the resulting dataframe back to the same variable.\n",
    "housing_df = housing_df[1:160]\n",
    "\n",
    "# Look at what's in the dataframe object.\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting your own index labels\n",
    "What if we decide that we want each county name to be our index instead of these numbers? We might want this so that we can refer to the county names as our row labels.\n",
    "\n",
    "First, we need to make sure that the counties in this dataset are unique. That is, that each one will uniquely identify a single row, and multiple rows don't accidentally (or intentionally) repeat county names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the values in a column are unique, and there are no duplicates.\n",
    "housing_df['county_name'].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: What would it look like to have duplicates?\n",
    "counties_dup_df = pd.DataFrame(['Appling', 'Atkinson', 'Bacon', 'Appling', 'Baker'], columns=['county_name'])\n",
    "\n",
    "# Look at what's in the dataframe object.\n",
    "counties_dup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if values in a column are unique.\n",
    "counties_dup_df['county_name'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See the number of times each value occurs.\n",
    "counties_dup_df['county_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change the dataframe index to a column and assign the resulting dataframe back to the same variable.\n",
    "housing_df = housing_df.set_index('county_name')\n",
    "\n",
    "# Look at the first few rows of the dataframe object, instead of the whole thing.\n",
    "housing_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the last few rows of the dataframe object, instead of the whole thing.\n",
    "housing_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Selecting values using row and column labels\n",
    "\n",
    "Now, the new index we created gives us row labels that are text (county names) instead of numbers. We can use the new labels to select and slice rows, instead of the positional index. \n",
    "\n",
    "We can also specify both rows *and* columns that we want to select using `DataFrame.loc[row_label, column_label]`. \n",
    "\n",
    "For rows these labels will be the index we specified, and for columns they will be the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a subset of data using labels.\n",
    "housing_df.loc['Treutlen':'Twiggs',[2000, 2011]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math functions on columns\n",
    "\n",
    "Let's answer the question: How much has the number of housing units changed for each county from 2000 to 2011?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the values in one column from the values in anothe.\n",
    "# Assign the result (a series) to a new column in the same dataframe.\n",
    "housing_df['housing_change'] = housing_df[2011] - housing_df[2000]\n",
    "\n",
    "# Look at the first few rows of the dataframe object.\n",
    "housing_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting data using criteria\n",
    "\n",
    "It looks like some counties actually had fewer housing units in 2011 than 2000. Let's see how we can find all of those, and answer the question: Which counties had fewer housing units in 2011 than in 2000? \n",
    "\n",
    "To do this, we can subset data based on criteria. \n",
    "\n",
    "- Equals: ==\n",
    "- Not equals: !=\n",
    "- Greater than, less than: > or <\n",
    "- Greater than or equal to: >=\n",
    "- Less than or equal to: <="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Subset data based on criteria using a \"boolean mask\". \n",
    "# Assign the resulting dataframe to a new variable.\n",
    "fewer_housing_units_df = housing_df[housing_df['housing_change'] < 0]\n",
    "\n",
    "# Look at what's in the dataframe object.\n",
    "fewer_housing_units_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about using Boolean masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a boolean (True/False) series based on the dataframe.\n",
    "housing_df['housing_change'] < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the series to a variable.\n",
    "mask = housing_df['housing_change'] < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the variable to choose rows from the dataframe that match with \"True\".\n",
    "housing_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do it all in one line.\n",
    "housing_df[housing_df['housing_change'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting data using column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a subset of data using column names and assign the resulting dataframe to the same variable.\n",
    "fewer_housing_units_df = fewer_housing_units_df[[2000, 2011,'housing_change']]\n",
    "\n",
    "# Look at what's in the dataframe object.\n",
    "fewer_housing_units_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to a CSV file.\n",
    "fewer_housing_units_df.to_csv(\"counties_with_fewer_housing_units.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data from two dataframes\n",
    "\n",
    "You can merge (aka \"join\") two dataframes using the `pd.merge()` function in order to combine data into a single dataframe. Before doing this, we need to get a new dataset and clean it up.\n",
    "\n",
    "I happen found the Governor's Office of Student Acheivement, Georgia School Grade Reports [datasets](https://schoolgrades.georgia.gov/dataset), and downloaded School-Level Data for the 2019 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data from a CSV file into a new `pandas` dataframe object.\n",
    "schools_df = pd.read_csv(\"school-19.csv\")\n",
    "\n",
    "# Look at what's in the dataframe object.\n",
    "schools_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at all the column names.\n",
    "schools_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose a subset of data using column names and assign the resulting dataframe to the same variable.\n",
    "schools_df = schools_df[['SystemName', \n",
    "                         'SchoolName', \n",
    "                         'Zip_Code',\n",
    "                         'total_enroll', \n",
    "                         'Grades', \n",
    "                         'Grade']]\n",
    "\n",
    "# Look at the first few rows of the dataframe object.\n",
    "schools_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent: A rant about naming things\n",
    "\n",
    "This is crazy! To use this data, you not only need to know the column names but also keep track of how each one is written, because you can't assume that a standard naming convention is being used.\n",
    "\n",
    "**?!?** The columns we pulled out use three different naming conventions **?!?**\n",
    "\n",
    "- Capitalized words with no space indicator (\"SystemName\")\n",
    "- Capitalized words with underscores (\"\\_\") for spaces (\"Zip_Code\")\n",
    "- All lower case with underscores (\"\\_\") for spaces (\"total_enroll\")\n",
    "\n",
    "\n",
    "It's worth learning about [Tidy Data](https://vita.had.co.nz/papers/tidy-data.pdf) to make your life easier. Choose one convention, name/rename columns, and sticking to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing values in a column (a quick look)\n",
    "\n",
    "We can also find and replace values in a column. In this data, we want to remove the word \"County\" after the county names in the `SystemName` column.\n",
    "\n",
    "Learn more about the power of [`DataFrame.replace()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) and regular expressions (regex)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace part of a string with nothing.\n",
    "schools_df = schools_df.replace(to_replace=\" County\", value=\"\", regex=True)\n",
    "\n",
    "# Look at the first few rows of the dataframe object.\n",
    "schools_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge dataframes on the values in a particular column that you expect them to have in common.\n",
    "merged_df = pd.merge(left=schools_df, right=fewer_housing_units_df, left_on='SystemName', \n",
    "                        right_on='county_name')\n",
    "\n",
    "# Look at what's in the dataframe.\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data into and out of a database with Python\n",
    "\n",
    "## Intro\n",
    "In some cases the data you want to access may be in a database, or you may want to put data into a database.\n",
    "\n",
    "Since I'm talking about tabular data, I'm going to focus on relational databases. These databases make sense when the amount of data you're working with gets large, and a system for managing the relationships between data in different tables matters.\n",
    "\n",
    "Here we'll assume we have access to an existing database. For reference, a \"simple\" database engine you can start with is SQLite, learn more about SQLite [here](https://www.sqlite.org/index.html).\n",
    "\n",
    "## Database adapters\n",
    "If you're already using Python to manipulate data, you can use an adapter to connect to a database within your code:\n",
    "\n",
    "- `sqlite3` for [SQLite databases](https://docs.python.org/3/library/sqlite3.html)\n",
    "- `psycopg2` for [PostgreSQL databases](https://www.psycopg.org/docs/usage.html)\n",
    "- `mysql-connector-python` for [MySQL databases](https://www.w3schools.com/python/python_mysql_getstarted.asp)\n",
    "\n",
    "## Overview\n",
    "The `sqlite3` module provides an interface for interacting with SQLite databases. It'll be my example for how using  database adapters works in Python.\n",
    "\n",
    "1. First, create a Connection object ito represent the database using `sqlite3.connect()`. \n",
    "2. Once you have a Connection, create a Cursor object with the `.cursor()`.\n",
    "3. The Cursor can perform all kinds of SQL (Structured Query Language) commands with the `.execute()` method.\n",
    "4. Use `.commit()` to optionally save changes to the database.\n",
    "5. When done, close the connection with `.close()`.\n",
    "\n",
    "**Flow**: open connection -> create cursor -> execute SQL commands -> *commit changes ->* close connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `sqlite3` module.\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a database.\n",
    "# Note: SQLite databases are files, database engines with servers will require more parameters in order to connect.\n",
    "conn = sqlite3.connect('example.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor to execute commands.\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the cursor to work with the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute an SQL query to create a new database table.\n",
    "sql_create_table = '''\n",
    "    CREATE TABLE tree\n",
    "    (id INT PRIMARY KEY NOT NULL,\n",
    "    name TEXT NOT NULL,\n",
    "    description TEXT,\n",
    "    rating REAL);\n",
    "    '''  \n",
    "\n",
    "c.execute(sql_create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute an SQL query to add data (one record) into a table.\n",
    "\n",
    "# The `sqlite3` module uses \"?\" as a placeholder wherever you want to use a value. \n",
    "# You then provide a tuple of values as the second argument to the cursor’s `execute()` method.\n",
    "# Note: Other database modules may use a different placeholder, for example `psycopg2` uses \"%s\".\n",
    "tree_record = (1, 'Sassafras', \"mitten-shaped and trilobed leaves\", 8)\n",
    "sql_insert = \"INSERT INTO tree (id, name, description, rating) VALUES (?,?,?,?);\"\n",
    "\n",
    "c.execute(sql_insert, tree_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute an SQL query to add data (multiple records) into a table.\n",
    "tree_records = [(2, 'American Hornbeam', 'muscular trunk', 7.75),\n",
    "                (3, 'Flowering Dogwood', 'stinky flowers', 6.50),\n",
    "                (4, 'Bald Cypress', 'knobby knees', 10),\n",
    "                (5, 'Lacebark Elm', 'flaky bark', 6.25),  \n",
    "            ]\n",
    "c.executemany('INSERT INTO tree VALUES (?,?,?,?)', tree_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit changes to the database to make them persistent across sessions.\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Execute an SQL query to get data from an existing database table.\n",
    "c.execute(\"SELECT * FROM tree;\")\n",
    "\n",
    "# Fetch the results.\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cursor.fetchall()` fetches all the rows of a query result. It returns all the rows as a list of tuples. An empty list is returned if there is no record to fetch.\n",
    "\n",
    "`cursor.fetchmany(size)` returns the number of rows specified by size argument. When called repeatedly this method fetches the next set of rows of a query result and returns a list of tuples. If no more rows are available, it returns an empty list.\n",
    "\n",
    "`cursor.fetchone()` method returns a single record or None if no more rows are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, treat the cursor as an \"iterator\".\n",
    "for row in c.execute(\"SELECT * FROM tree;\"):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `pandas` to work with a database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use `pandas` to read data from a database table directly into a dataframe.\n",
    "tree_df = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT * FROM tree;\n",
    "    ''',\n",
    "    conn)\n",
    "\n",
    "# Look at what's in the dataframe.\n",
    "tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data from a dataframe directly into a database table.\n",
    "schools_df.to_sql(\"schools\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use cursor as an \"iterator\" to see rows in the new database table.\n",
    "for row in c.execute(\n",
    "    '''\n",
    "    SELECT \n",
    "        SchoolName,\n",
    "        Grades,\n",
    "        Grade\n",
    "    FROM schools\n",
    "    WHERE Grades is \"9-12\" and Grade is \"A\";\n",
    "    '''\n",
    "):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the cursor and database connection.\n",
    "if(conn):\n",
    "    c.close()\n",
    "    conn.close()\n",
    "    print(\"The database connection is closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
